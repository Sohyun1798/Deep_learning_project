{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "import torch\n",
    "from torch import optim\n",
    "\n",
    "from lib.suggested.self_attention_with_cnn import SelfAttentionCnnClassifier\n",
    "from lib.embedding import load_full_embedding_with_vocab\n",
    "from lib.reader import WikiqaReader, filtered_ref_generator\n",
    "from lib.train import train_model, get_label_score\n",
    "from lib.transformer import NoamOpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = 'models/suggested/self_attention_with_cnn/config.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(config_path, 'r') as fread:\n",
    "    config_dict = json.load(fread)\n",
    "\n",
    "# path\n",
    "path_config = config_dict['Path']\n",
    "model_dir = path_config['model_dir']\n",
    "train = path_config['train']\n",
    "dev = path_config['dev']\n",
    "dev_ref = path_config['dev_ref']\n",
    "test = path_config['test']\n",
    "test_ref = path_config['test_ref']\n",
    "\n",
    "words_embed, words_vocab = load_full_embedding_with_vocab(path_config['embed_dir'])\n",
    "vocabs = {'q_words': words_vocab, 'a_words': words_vocab}\n",
    "\n",
    "# model\n",
    "model_config = config_dict['Model']\n",
    "conv_width = model_config['conv_width']\n",
    "out_channels = model_config['out_channels']\n",
    "hidden_size = model_config['hidden_size']\n",
    "cuda_device = model_config['cuda_device']\n",
    "dropout = model_config['dropout']\n",
    "h = model_config['h']\n",
    "d_ff = model_config['d_ff']\n",
    "\n",
    "clf = SelfAttentionCnnClassifier(words_embed=words_embed, out_channels=out_channels,\n",
    "            conv_width=conv_width, hidden_size=hidden_size, cuda_device=None,\n",
    "            h=h, d_ff=d_ff, dropout=dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.load_state_dict(torch.load(os.path.join(model_dir, 'net.pt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_reader = WikiqaReader(dev, PAD_TOKEN='<pad>')\n",
    "dev_reader.set_vocabs(vocabs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load(os.path.join(model_dir, 'net.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['embed.weight', 'pos_enc.pe', 'q_mha1.linears.0.weight', 'q_mha1.linears.0.bias', 'q_mha1.linears.1.weight', 'q_mha1.linears.1.bias', 'q_mha1.linears.2.weight', 'q_mha1.linears.2.bias', 'q_mha1.linears.3.weight', 'q_mha1.linears.3.bias', 'q_mha2.linears.0.weight', 'q_mha2.linears.0.bias', 'q_mha2.linears.1.weight', 'q_mha2.linears.1.bias', 'q_mha2.linears.2.weight', 'q_mha2.linears.2.bias', 'q_mha2.linears.3.weight', 'q_mha2.linears.3.bias', 'q_ffn.w_1.weight', 'q_ffn.w_1.bias', 'q_ffn.w_2.weight', 'q_ffn.w_2.bias', 'q_layer_norms.0.weight', 'q_layer_norms.0.bias', 'q_layer_norms.1.weight', 'q_layer_norms.1.bias', 'q_layer_norms.2.weight', 'q_layer_norms.2.bias', 'a_mha1.linears.0.weight', 'a_mha1.linears.0.bias', 'a_mha1.linears.1.weight', 'a_mha1.linears.1.bias', 'a_mha1.linears.2.weight', 'a_mha1.linears.2.bias', 'a_mha1.linears.3.weight', 'a_mha1.linears.3.bias', 'a_mha2.linears.0.weight', 'a_mha2.linears.0.bias', 'a_mha2.linears.1.weight', 'a_mha2.linears.1.bias', 'a_mha2.linears.2.weight', 'a_mha2.linears.2.bias', 'a_mha2.linears.3.weight', 'a_mha2.linears.3.bias', 'a_ffn.w_1.weight', 'a_ffn.w_1.bias', 'a_ffn.w_2.weight', 'a_ffn.w_2.bias', 'a_layer_norms.0.weight', 'a_layer_norms.0.bias', 'a_layer_norms.1.weight', 'a_layer_norms.1.bias', 'a_layer_norms.2.weight', 'a_layer_norms.2.bias', 'q_conv.weight', 'q_conv.bias', 'a_conv.weight', 'a_conv.bias', 'hidden1.weight', 'hidden1.bias', 'hidden2.weight', 'hidden2.bias'])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(state_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(clf.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestModule(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TestModule, self).__init__()\n",
    "        self.linear = torch.nn.Linear(100, 100)\n",
    "        self.linears = torch.nn.ModuleList([torch.nn.Linear(100, 100) for _ in range(3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_clf = TestModule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['linear.weight', 'linear.bias', 'linears.0.weight', 'linears.0.bias', 'linears.1.weight', 'linears.1.bias', 'linears.2.weight', 'linears.2.bias'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_clf.state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(test_clf.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['embed.weight', 'conv1.weight', 'conv1.bias', 'convs.0.weight', 'convs.0.bias', 'convs.1.weight', 'convs.1.bias', 'convs.2.weight', 'convs.2.bias', 'hidden1.weight', 'hidden1.bias', 'hidden2.weight', 'hidden2.bias'])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load('models/baseline/focus/net.pt').keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_iterator = dev_reader.get_dataset_iterator(10, train=False, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(dev_iterator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[torchtext.data.batch.Batch of size 10]\n",
       "\t[.q_words]:[torch.LongTensor of size 10x9]\n",
       "\t[.a_words]:[torch.LongTensor of size 10x52]\n",
       "\t[.label]:[torch.LongTensor of size 10]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_words = batch.q_words.cuda()\n",
    "a_words = batch.a_words.cuda()\n",
    "label = batch.label.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_words = batch.q_words\n",
    "a_words = batch.a_words\n",
    "label = batch.label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(2470721, 50)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.embed.weight[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.embed.weight[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.3599, -0.9806,  0.6490,  0.6391, -0.3194,  0.4745,  0.0142, -0.5854,\n",
       "        -0.1329, -0.3566,  1.4825,  0.6276, -0.4546, -0.3539, -0.0517,  0.4643,\n",
       "        -1.0893,  0.0997,  0.2904,  0.3147,  0.1732,  0.8788, -0.0925,  0.4679,\n",
       "         0.0924, -0.6042,  1.2915, -0.6668, -0.6697,  0.0316,  0.4964,  0.2767,\n",
       "         0.1808, -0.7954,  0.4086,  1.1201,  0.0318,  1.1545,  0.0073,  0.6567,\n",
       "         0.3457, -0.1024, -0.8479,  0.1636,  0.1643,  0.3092, -1.2851,  1.1663,\n",
       "         0.2186,  1.0116])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.embed.weight[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1012269,  355012, 1074972,  374572, 1997409, 1049602, 1011785,   40530,\n",
       "        2201719])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_words[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0153,  0.1667, -0.2303, -0.0355, -0.3398, -0.2279, -0.1315,  0.0350,\n",
       "          0.0603, -0.0577, -0.1365,  0.0305, -0.2955,  0.0547,  0.0520,  0.0665,\n",
       "         -0.5095,  0.0924, -0.2522,  0.2532, -0.3016, -0.1758,  0.0277, -0.2793,\n",
       "         -0.1166, -0.0111,  0.1673,  0.0854, -0.1373, -0.0949, -0.3816, -0.0853,\n",
       "         -0.2936, -0.1023, -0.4602,  0.0628,  0.4433, -0.2157,  0.4328, -0.1458,\n",
       "          0.1549, -0.5446,  0.4038, -0.0261,  0.2631, -0.0451,  0.0474,  0.0143,\n",
       "         -0.4142, -0.0857],\n",
       "        [-0.1885, -0.0042, -0.2205, -0.0547,  0.1802, -0.1991, -0.0735, -0.1208,\n",
       "          0.0293, -0.3213, -0.0603, -0.3856, -0.0209,  0.0646, -0.2272,  0.0169,\n",
       "         -0.5267,  0.1348, -0.2191,  0.0507, -0.3143,  0.1263, -0.1166, -0.2018,\n",
       "          0.2915, -0.1627,  0.0612,  0.1495,  0.0466, -0.2522, -0.2725,  0.0968,\n",
       "         -0.3424,  0.1331,  0.0169, -0.2545,  0.0585,  0.0785, -0.1787, -0.4401,\n",
       "         -0.0577, -0.2181,  0.0790,  0.1681,  0.1416,  0.4151, -0.2538, -0.3202,\n",
       "         -0.1337,  0.0526],\n",
       "        [-0.0590,  0.4907, -0.1367, -0.1610,  0.0636, -0.0809, -0.1528,  0.2405,\n",
       "         -0.1251, -0.0511, -0.1285, -0.1148,  0.0060,  0.1703,  0.1695,  0.0480,\n",
       "         -0.1420, -0.0424, -0.5657, -0.0639, -0.0944, -0.2768, -0.0712, -0.1529,\n",
       "         -0.0010, -0.1181,  0.1615, -0.2215, -0.3572,  0.1979, -0.1455,  0.0892,\n",
       "         -0.1793, -0.4107, -0.0180,  0.1546, -0.1996, -0.1544, -0.1433, -0.4153,\n",
       "         -0.1357,  0.0647, -0.4846, -0.2420,  0.2722,  0.0196, -0.0711, -0.0004,\n",
       "         -0.1227, -0.1360],\n",
       "        [ 0.1247, -0.4387, -0.0803, -0.0715, -0.0860, -0.4097, -0.5736,  0.3203,\n",
       "         -0.0850, -0.1493, -0.4888, -0.3933,  0.1571,  0.0148, -0.2190,  0.0359,\n",
       "          0.3246,  0.2655, -0.2220,  0.1838, -0.1725,  0.0482,  0.2980,  0.3657,\n",
       "          0.1882, -0.2817, -0.1665, -0.1659,  0.0523,  0.1227, -0.2223,  0.3109,\n",
       "         -0.1824, -0.5190, -0.2018,  0.2024, -0.2128,  0.1030,  0.1918,  0.2355,\n",
       "         -0.0862, -0.1423, -0.1241, -0.3634, -0.3233,  0.1029, -0.2007, -0.1050,\n",
       "         -0.0534,  0.3139],\n",
       "        [-0.3404, -0.6952,  0.0498, -0.1277,  0.0581, -0.1971, -0.2922,  0.4703,\n",
       "         -0.0280,  0.1861, -0.3700, -0.2317, -0.0872,  0.1144,  0.1410, -0.0188,\n",
       "         -0.2140, -0.0861, -0.2401,  0.5714, -0.3970, -0.5069,  0.4046,  0.0560,\n",
       "         -0.0084, -0.0580,  0.3996,  0.2626,  0.0287,  0.0923, -0.0093,  0.5811,\n",
       "         -0.2973, -0.6107, -0.0747,  0.0615, -0.3871, -0.6410,  0.3369,  0.1047,\n",
       "          0.0015, -0.2916, -0.1742, -0.4186, -0.0234,  0.2065, -0.6158,  0.0045,\n",
       "         -0.2617,  0.7092],\n",
       "        [ 0.1027,  0.2431, -0.0924, -0.1338, -0.0596,  0.2238,  0.0083,  0.0134,\n",
       "          0.0661, -0.0294,  0.0216, -0.1156,  0.2525, -0.0190, -0.1636, -0.2598,\n",
       "         -0.2910,  0.0469, -0.3419, -0.0366, -0.1696, -0.0082,  0.0906,  0.2071,\n",
       "          0.1845, -0.2507,  0.0582, -0.0257, -0.4095,  0.0734, -0.0949,  0.1635,\n",
       "         -0.2101, -0.2539, -0.1931,  0.1974,  0.2230, -0.0488,  0.0235, -0.2124,\n",
       "          0.0091, -0.1397,  0.1740, -0.0766, -0.0097, -0.0198, -0.1599, -0.1255,\n",
       "         -0.4254,  0.2351],\n",
       "        [ 0.3059, -0.2014, -0.2677, -0.1148,  0.1621, -0.2275,  0.2054, -0.2284,\n",
       "          0.1788, -0.5421, -0.1142, -0.1933, -0.1194,  0.0325, -0.2326, -0.0658,\n",
       "         -0.4029,  0.2163, -0.1221, -0.5747, -0.4087, -0.1673, -0.0064,  0.0555,\n",
       "          0.2332, -0.1790, -0.1720,  0.1409, -0.2664, -0.0309, -0.2254,  0.5207,\n",
       "          0.0395, -0.2572,  0.4141, -0.1795,  0.6297,  0.0919,  0.3421, -0.4208,\n",
       "         -0.4891,  0.0980, -0.0308,  0.1614, -0.3673,  0.4696, -0.0640, -0.1609,\n",
       "         -0.0274,  0.1008],\n",
       "        [ 0.1958, -0.7127,  0.3720,  0.4309, -0.1165, -0.2154,  0.1805,  0.1142,\n",
       "         -0.0403,  0.0897,  1.0935,  0.0537,  0.0865, -0.1853,  0.4675,  0.2620,\n",
       "         -0.4505,  0.0035,  0.1736,  0.4813, -0.0299,  0.2872, -0.2643,  0.0602,\n",
       "         -0.2315, -0.4218,  0.5085, -0.3394, -0.0975,  0.4450,  0.1403, -0.1601,\n",
       "         -0.4693, -0.2967,  0.5389,  0.1601, -0.3448,  0.1482,  0.3628,  0.1144,\n",
       "         -0.2754,  0.5877, -0.3973,  0.4714, -0.0396,  0.4029,  0.1944,  0.4471,\n",
       "          0.3583,  0.0318],\n",
       "        [ 0.1910, -0.0359, -0.2472,  0.2205,  0.4973, -0.4960,  0.1441, -0.0182,\n",
       "          0.3339, -0.0825, -0.0945, -0.4667, -0.3817,  0.0134, -0.5419, -0.1489,\n",
       "         -0.2722,  0.4994,  0.1398, -0.4321, -0.3561, -0.4349,  0.2611,  0.2528,\n",
       "          0.3829, -0.3243, -0.2475, -0.2162, -0.4281, -0.2314, -0.5194,  0.4812,\n",
       "          0.1616, -0.6036,  0.3436, -0.5032,  0.4634,  0.0088,  0.2975, -0.2862,\n",
       "         -0.4765,  0.1097,  0.1918, -0.3366, -0.5442,  0.7312, -0.1593, -0.0887,\n",
       "          0.3494,  0.0043]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.embed(q_words[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 374572, 1997409,   40530, 1050505, 1074972,  214259,  209213,  543469,\n",
       "        2013082, 1049602,  428200, 1931636, 1347365,   16617,  415949,   39867,\n",
       "        1997409,   41681,       1,       1,       1,       1,       1,       1,\n",
       "              1,       1,       1,       1,       1,       1,       1,       1,\n",
       "              1,       1,       1,       1,       1,       1,       1,       1,\n",
       "              1,       1,       1,       1,       1,       1,       1,       1,\n",
       "              1,       1,       1,       1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_words[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1247, -0.4387, -0.0803,  ..., -0.1050, -0.0534,  0.3139],\n",
       "        [-0.3404, -0.6952,  0.0498,  ...,  0.0045, -0.2617,  0.7092],\n",
       "        [ 0.1958, -0.7127,  0.3720,  ...,  0.4471,  0.3583,  0.0318],\n",
       "        ...,\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.embed(a_words[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_sent_mat = clf.embed(q_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_sent_mat = clf.embed(a_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0153,  0.1667, -0.2303,  ...,  0.0143, -0.4142, -0.0857],\n",
       "         [-0.1885, -0.0042, -0.2205,  ..., -0.3202, -0.1337,  0.0526],\n",
       "         [-0.0590,  0.4907, -0.1367,  ..., -0.0004, -0.1227, -0.1360],\n",
       "         ...,\n",
       "         [ 0.3059, -0.2014, -0.2677,  ..., -0.1609, -0.0274,  0.1008],\n",
       "         [ 0.1958, -0.7127,  0.3720,  ...,  0.4471,  0.3583,  0.0318],\n",
       "         [ 0.1910, -0.0359, -0.2472,  ..., -0.0887,  0.3494,  0.0043]],\n",
       "\n",
       "        [[-0.0153,  0.1667, -0.2303,  ...,  0.0143, -0.4142, -0.0857],\n",
       "         [-0.1885, -0.0042, -0.2205,  ..., -0.3202, -0.1337,  0.0526],\n",
       "         [-0.0590,  0.4907, -0.1367,  ..., -0.0004, -0.1227, -0.1360],\n",
       "         ...,\n",
       "         [ 0.3059, -0.2014, -0.2677,  ..., -0.1609, -0.0274,  0.1008],\n",
       "         [ 0.1958, -0.7127,  0.3720,  ...,  0.4471,  0.3583,  0.0318],\n",
       "         [ 0.1910, -0.0359, -0.2472,  ..., -0.0887,  0.3494,  0.0043]],\n",
       "\n",
       "        [[-0.0153,  0.1667, -0.2303,  ...,  0.0143, -0.4142, -0.0857],\n",
       "         [-0.1885, -0.0042, -0.2205,  ..., -0.3202, -0.1337,  0.0526],\n",
       "         [-0.0590,  0.4907, -0.1367,  ..., -0.0004, -0.1227, -0.1360],\n",
       "         ...,\n",
       "         [ 0.3059, -0.2014, -0.2677,  ..., -0.1609, -0.0274,  0.1008],\n",
       "         [ 0.1958, -0.7127,  0.3720,  ...,  0.4471,  0.3583,  0.0318],\n",
       "         [ 0.1910, -0.0359, -0.2472,  ..., -0.0887,  0.3494,  0.0043]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.0153,  0.1667, -0.2303,  ...,  0.0143, -0.4142, -0.0857],\n",
       "         [ 0.0032,  0.4325, -0.0192,  ..., -0.2333, -0.2614,  0.0034],\n",
       "         [ 0.0240,  0.3182,  0.0037,  ..., -0.3199, -0.4138, -0.1077],\n",
       "         ...,\n",
       "         [-0.1293,  0.3852,  0.0342,  ..., -0.2211, -0.4378,  0.2269],\n",
       "         [ 0.0010,  0.3846, -0.3412,  ..., -0.0610, -0.1496,  0.0914],\n",
       "         [-0.2083,  0.0272, -0.0910,  ..., -0.1215,  0.0462,  0.0214]],\n",
       "\n",
       "        [[-0.0153,  0.1667, -0.2303,  ...,  0.0143, -0.4142, -0.0857],\n",
       "         [ 0.0032,  0.4325, -0.0192,  ..., -0.2333, -0.2614,  0.0034],\n",
       "         [ 0.0240,  0.3182,  0.0037,  ..., -0.3199, -0.4138, -0.1077],\n",
       "         ...,\n",
       "         [-0.1293,  0.3852,  0.0342,  ..., -0.2211, -0.4378,  0.2269],\n",
       "         [ 0.0010,  0.3846, -0.3412,  ..., -0.0610, -0.1496,  0.0914],\n",
       "         [-0.2083,  0.0272, -0.0910,  ..., -0.1215,  0.0462,  0.0214]],\n",
       "\n",
       "        [[-0.0153,  0.1667, -0.2303,  ...,  0.0143, -0.4142, -0.0857],\n",
       "         [ 0.0032,  0.4325, -0.0192,  ..., -0.2333, -0.2614,  0.0034],\n",
       "         [ 0.0240,  0.3182,  0.0037,  ..., -0.3199, -0.4138, -0.1077],\n",
       "         ...,\n",
       "         [-0.1293,  0.3852,  0.0342,  ..., -0.2211, -0.4378,  0.2269],\n",
       "         [ 0.0010,  0.3846, -0.3412,  ..., -0.0610, -0.1496,  0.0914],\n",
       "         [-0.2083,  0.0272, -0.0910,  ..., -0.1215,  0.0462,  0.0214]]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_sent_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1247, -0.4387, -0.0803,  ..., -0.1050, -0.0534,  0.3139],\n",
       "         [-0.3404, -0.6952,  0.0498,  ...,  0.0045, -0.2617,  0.7092],\n",
       "         [ 0.1958, -0.7127,  0.3720,  ...,  0.4471,  0.3583,  0.0318],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.0283,  0.1306, -0.1471,  ...,  0.6354, -0.4958,  0.8075],\n",
       "         [ 0.1027,  0.2431, -0.0924,  ..., -0.1255, -0.4254,  0.2351],\n",
       "         [ 0.3059, -0.2014, -0.2677,  ..., -0.1609, -0.0274,  0.1008],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[-0.3069,  0.4625, -0.1742,  ...,  0.6627,  0.1058,  0.2023],\n",
       "         [ 0.0010,  0.3846, -0.3412,  ..., -0.0610, -0.1496,  0.0914],\n",
       "         [-0.1870,  0.2239,  0.3036,  ..., -0.0133, -0.5382,  0.1786],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.0027,  0.0513, -0.0694,  ..., -0.2580, -0.5666, -0.0681],\n",
       "         [ 0.0010,  0.3846, -0.3412,  ..., -0.0610, -0.1496,  0.0914],\n",
       "         [-0.1538, -0.1673,  0.0997,  ...,  0.0819, -0.2534,  0.2166],\n",
       "         ...,\n",
       "         [-0.1664, -0.1651,  0.0776,  ...,  0.4590, -0.2381, -0.0240],\n",
       "         [-0.1691, -0.0526,  0.0767,  ...,  0.1836, -0.2790,  0.1950],\n",
       "         [-0.2677, -0.8802,  0.7641,  ...,  0.8275,  0.4071,  0.1360]],\n",
       "\n",
       "        [[ 0.1456,  0.0535,  0.1065,  ...,  0.7326,  0.0903,  0.0369],\n",
       "         [ 0.0030,  0.0570,  0.0293,  ...,  0.0940, -0.4541, -0.3108],\n",
       "         [ 0.3627, -0.0786,  0.2483,  ..., -0.2010, -0.5667, -0.2275],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.1456,  0.0535,  0.1065,  ...,  0.7326,  0.0903,  0.0369],\n",
       "         [ 0.0030,  0.0570,  0.0293,  ...,  0.0940, -0.4541, -0.3108],\n",
       "         [ 0.3627, -0.0786,  0.2483,  ..., -0.2010, -0.5667, -0.2275],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_sent_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MultiHeadedAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiHeadedAttention(\n",
       "  (dropout): Dropout(p=0.3)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.q_mha1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Linear(in_features=50, out_features=50, bias=True),\n",
       " Linear(in_features=50, out_features=50, bias=True),\n",
       " Linear(in_features=50, out_features=50, bias=True),\n",
       " Linear(in_features=50, out_features=50, bias=True)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.q_mha1.linears"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0877,  0.0912, -0.0862,  ...,  0.1060,  0.0327, -0.1133],\n",
       "        [-0.1075,  0.1384, -0.0464,  ..., -0.0074,  0.1035, -0.0381],\n",
       "        [-0.0514, -0.1118,  0.0545,  ...,  0.0665,  0.0012, -0.0602],\n",
       "        ...,\n",
       "        [ 0.1164,  0.0207,  0.0032,  ...,  0.0822,  0.0012, -0.1042],\n",
       "        [ 0.0724,  0.0514, -0.0262,  ...,  0.0692, -0.1114,  0.0206],\n",
       "        [-0.0266,  0.1147, -0.0986,  ...,  0.0769, -0.0296,  0.0122]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.q_mha1.linears[0].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0808, grad_fn=<StdBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.q_mha1.linears[0].weight.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.0050, grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.q_mha1.linears[0].weight.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_mask = (q_words > 1).unsqueeze(-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_mask = (a_words > 1).unsqueeze(-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1, 9])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_mask.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1, 52])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_mask.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([-0.0482,  0.1396, -0.0015, -0.1236, -0.0139, -0.1201,  0.0278, -0.1357,\n",
       "         0.1287,  0.1272,  0.1220,  0.0316, -0.0779, -0.0061, -0.0075,  0.1313,\n",
       "        -0.1304, -0.0600, -0.0348,  0.0143, -0.1155, -0.0555, -0.0945, -0.1112,\n",
       "        -0.0034,  0.0828, -0.1038,  0.1385,  0.0880,  0.1238, -0.0221,  0.0318,\n",
       "         0.1118,  0.0175, -0.0107,  0.0230, -0.1216,  0.0024,  0.1090, -0.0051,\n",
       "        -0.0890,  0.1279,  0.1500, -0.0749, -0.0975,  0.1205, -0.0254,  0.0247,\n",
       "         0.0045, -0.0044], requires_grad=True)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.q_mha1.linears[0].bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = clf.q_mha1.linears[0](q_sent_mat).split(h, dim=-1)[0]\n",
    "key = clf.q_mha1.linears[1](q_sent_mat).split(h, dim=-1)[0]\n",
    "value = clf.q_mha1.linears[2](q_sent_mat).split(h, dim=-1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = torch.matmul(query, key.transpose(-2, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 9, 9])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0243, -0.0945,  0.0849, -0.0130,  0.2902, -0.3012,  0.0222, -0.2183,\n",
       "         0.3818,  0.0180], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1021, -0.1784,  0.0670, -0.2595, -0.2801, -0.1237,  0.1974, -0.1476,\n",
       "        -0.4013, -0.0143], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0984, 0.1281, 0.1084, 0.1029, 0.1221, 0.1020, 0.1174, 0.0989,\n",
       "          0.1218],\n",
       "         [0.1101, 0.1226, 0.1107, 0.1038, 0.1218, 0.1060, 0.1086, 0.1040,\n",
       "          0.1123],\n",
       "         [0.1124, 0.1124, 0.1102, 0.1081, 0.1248, 0.1080, 0.1027, 0.1160,\n",
       "          0.1055],\n",
       "         [0.1146, 0.1083, 0.1091, 0.1112, 0.1217, 0.1057, 0.1033, 0.1207,\n",
       "          0.1054],\n",
       "         [0.1052, 0.1160, 0.1074, 0.1098, 0.1353, 0.1002, 0.1091, 0.1059,\n",
       "          0.1111],\n",
       "         [0.1107, 0.1167, 0.1127, 0.1047, 0.1241, 0.1076, 0.1073, 0.1045,\n",
       "          0.1117],\n",
       "         [0.1064, 0.1153, 0.1080, 0.1058, 0.1281, 0.1076, 0.1079, 0.1054,\n",
       "          0.1157],\n",
       "         [0.1240, 0.1045, 0.1070, 0.1207, 0.1263, 0.1093, 0.0947, 0.1227,\n",
       "          0.0908],\n",
       "         [0.0973, 0.1124, 0.1042, 0.0996, 0.1179, 0.1059, 0.1172, 0.1128,\n",
       "          0.1326]],\n",
       "\n",
       "        [[0.0984, 0.1281, 0.1084, 0.1029, 0.1221, 0.1020, 0.1174, 0.0989,\n",
       "          0.1218],\n",
       "         [0.1101, 0.1226, 0.1107, 0.1038, 0.1218, 0.1060, 0.1086, 0.1040,\n",
       "          0.1123],\n",
       "         [0.1124, 0.1124, 0.1102, 0.1081, 0.1248, 0.1080, 0.1027, 0.1160,\n",
       "          0.1055],\n",
       "         [0.1146, 0.1083, 0.1091, 0.1112, 0.1217, 0.1057, 0.1033, 0.1207,\n",
       "          0.1054],\n",
       "         [0.1052, 0.1160, 0.1074, 0.1098, 0.1353, 0.1002, 0.1091, 0.1059,\n",
       "          0.1111],\n",
       "         [0.1107, 0.1167, 0.1127, 0.1047, 0.1241, 0.1076, 0.1073, 0.1045,\n",
       "          0.1117],\n",
       "         [0.1064, 0.1153, 0.1080, 0.1058, 0.1281, 0.1076, 0.1079, 0.1054,\n",
       "          0.1157],\n",
       "         [0.1240, 0.1045, 0.1070, 0.1207, 0.1263, 0.1093, 0.0947, 0.1227,\n",
       "          0.0908],\n",
       "         [0.0973, 0.1124, 0.1042, 0.0996, 0.1179, 0.1059, 0.1172, 0.1128,\n",
       "          0.1326]],\n",
       "\n",
       "        [[0.0984, 0.1281, 0.1084, 0.1029, 0.1221, 0.1020, 0.1174, 0.0989,\n",
       "          0.1218],\n",
       "         [0.1101, 0.1226, 0.1107, 0.1038, 0.1218, 0.1060, 0.1086, 0.1040,\n",
       "          0.1123],\n",
       "         [0.1124, 0.1124, 0.1102, 0.1081, 0.1248, 0.1080, 0.1027, 0.1160,\n",
       "          0.1055],\n",
       "         [0.1146, 0.1083, 0.1091, 0.1112, 0.1217, 0.1057, 0.1033, 0.1207,\n",
       "          0.1054],\n",
       "         [0.1052, 0.1160, 0.1074, 0.1098, 0.1353, 0.1002, 0.1091, 0.1059,\n",
       "          0.1111],\n",
       "         [0.1107, 0.1167, 0.1127, 0.1047, 0.1241, 0.1076, 0.1073, 0.1045,\n",
       "          0.1117],\n",
       "         [0.1064, 0.1153, 0.1080, 0.1058, 0.1281, 0.1076, 0.1079, 0.1054,\n",
       "          0.1157],\n",
       "         [0.1240, 0.1045, 0.1070, 0.1207, 0.1263, 0.1093, 0.0947, 0.1227,\n",
       "          0.0908],\n",
       "         [0.0973, 0.1124, 0.1042, 0.0996, 0.1179, 0.1059, 0.1172, 0.1128,\n",
       "          0.1326]],\n",
       "\n",
       "        [[0.0984, 0.1281, 0.1084, 0.1029, 0.1221, 0.1020, 0.1174, 0.0989,\n",
       "          0.1218],\n",
       "         [0.1101, 0.1226, 0.1107, 0.1038, 0.1218, 0.1060, 0.1086, 0.1040,\n",
       "          0.1123],\n",
       "         [0.1124, 0.1124, 0.1102, 0.1081, 0.1248, 0.1080, 0.1027, 0.1160,\n",
       "          0.1055],\n",
       "         [0.1146, 0.1083, 0.1091, 0.1112, 0.1217, 0.1057, 0.1033, 0.1207,\n",
       "          0.1054],\n",
       "         [0.1052, 0.1160, 0.1074, 0.1098, 0.1353, 0.1002, 0.1091, 0.1059,\n",
       "          0.1111],\n",
       "         [0.1107, 0.1167, 0.1127, 0.1047, 0.1241, 0.1076, 0.1073, 0.1045,\n",
       "          0.1117],\n",
       "         [0.1064, 0.1153, 0.1080, 0.1058, 0.1281, 0.1076, 0.1079, 0.1054,\n",
       "          0.1157],\n",
       "         [0.1240, 0.1045, 0.1070, 0.1207, 0.1263, 0.1093, 0.0947, 0.1227,\n",
       "          0.0908],\n",
       "         [0.0973, 0.1124, 0.1042, 0.0996, 0.1179, 0.1059, 0.1172, 0.1128,\n",
       "          0.1326]],\n",
       "\n",
       "        [[0.0984, 0.1281, 0.1084, 0.1029, 0.1221, 0.1020, 0.1174, 0.0989,\n",
       "          0.1218],\n",
       "         [0.1101, 0.1226, 0.1107, 0.1038, 0.1218, 0.1060, 0.1086, 0.1040,\n",
       "          0.1123],\n",
       "         [0.1124, 0.1124, 0.1102, 0.1081, 0.1248, 0.1080, 0.1027, 0.1160,\n",
       "          0.1055],\n",
       "         [0.1146, 0.1083, 0.1091, 0.1112, 0.1217, 0.1057, 0.1033, 0.1207,\n",
       "          0.1054],\n",
       "         [0.1052, 0.1160, 0.1074, 0.1098, 0.1353, 0.1002, 0.1091, 0.1059,\n",
       "          0.1111],\n",
       "         [0.1107, 0.1167, 0.1127, 0.1047, 0.1241, 0.1076, 0.1073, 0.1045,\n",
       "          0.1117],\n",
       "         [0.1064, 0.1153, 0.1080, 0.1058, 0.1281, 0.1076, 0.1079, 0.1054,\n",
       "          0.1157],\n",
       "         [0.1240, 0.1045, 0.1070, 0.1207, 0.1263, 0.1093, 0.0947, 0.1227,\n",
       "          0.0908],\n",
       "         [0.0973, 0.1124, 0.1042, 0.0996, 0.1179, 0.1059, 0.1172, 0.1128,\n",
       "          0.1326]],\n",
       "\n",
       "        [[0.1050, 0.1125, 0.1082, 0.1177, 0.1079, 0.1078, 0.1175, 0.1159,\n",
       "          0.1074],\n",
       "         [0.1163, 0.1084, 0.1113, 0.1164, 0.1122, 0.0987, 0.1225, 0.1116,\n",
       "          0.1025],\n",
       "         [0.1061, 0.1098, 0.1136, 0.1253, 0.1095, 0.0967, 0.1123, 0.1147,\n",
       "          0.1119],\n",
       "         [0.1111, 0.1036, 0.1047, 0.1370, 0.1215, 0.1052, 0.1068, 0.1055,\n",
       "          0.1047],\n",
       "         [0.1067, 0.1134, 0.1068, 0.1265, 0.1094, 0.0961, 0.1133, 0.1233,\n",
       "          0.1045],\n",
       "         [0.1114, 0.1017, 0.1069, 0.1390, 0.1128, 0.1041, 0.1106, 0.1085,\n",
       "          0.1049],\n",
       "         [0.1089, 0.1098, 0.1132, 0.1163, 0.1128, 0.1007, 0.1188, 0.1122,\n",
       "          0.1073],\n",
       "         [0.1108, 0.1064, 0.1082, 0.1247, 0.1145, 0.1065, 0.1182, 0.1050,\n",
       "          0.1057],\n",
       "         [0.1025, 0.1163, 0.1173, 0.1075, 0.1068, 0.0992, 0.1205, 0.1175,\n",
       "          0.1122]],\n",
       "\n",
       "        [[0.1050, 0.1125, 0.1082, 0.1177, 0.1079, 0.1078, 0.1175, 0.1159,\n",
       "          0.1074],\n",
       "         [0.1163, 0.1084, 0.1113, 0.1164, 0.1122, 0.0987, 0.1225, 0.1116,\n",
       "          0.1025],\n",
       "         [0.1061, 0.1098, 0.1136, 0.1253, 0.1095, 0.0967, 0.1123, 0.1147,\n",
       "          0.1119],\n",
       "         [0.1111, 0.1036, 0.1047, 0.1370, 0.1215, 0.1052, 0.1068, 0.1055,\n",
       "          0.1047],\n",
       "         [0.1067, 0.1134, 0.1068, 0.1265, 0.1094, 0.0961, 0.1133, 0.1233,\n",
       "          0.1045],\n",
       "         [0.1114, 0.1017, 0.1069, 0.1390, 0.1128, 0.1041, 0.1106, 0.1085,\n",
       "          0.1049],\n",
       "         [0.1089, 0.1098, 0.1132, 0.1163, 0.1128, 0.1007, 0.1188, 0.1122,\n",
       "          0.1073],\n",
       "         [0.1108, 0.1064, 0.1082, 0.1247, 0.1145, 0.1065, 0.1182, 0.1050,\n",
       "          0.1057],\n",
       "         [0.1025, 0.1163, 0.1173, 0.1075, 0.1068, 0.0992, 0.1205, 0.1175,\n",
       "          0.1122]],\n",
       "\n",
       "        [[0.1050, 0.1125, 0.1082, 0.1177, 0.1079, 0.1078, 0.1175, 0.1159,\n",
       "          0.1074],\n",
       "         [0.1163, 0.1084, 0.1113, 0.1164, 0.1122, 0.0987, 0.1225, 0.1116,\n",
       "          0.1025],\n",
       "         [0.1061, 0.1098, 0.1136, 0.1253, 0.1095, 0.0967, 0.1123, 0.1147,\n",
       "          0.1119],\n",
       "         [0.1111, 0.1036, 0.1047, 0.1370, 0.1215, 0.1052, 0.1068, 0.1055,\n",
       "          0.1047],\n",
       "         [0.1067, 0.1134, 0.1068, 0.1265, 0.1094, 0.0961, 0.1133, 0.1233,\n",
       "          0.1045],\n",
       "         [0.1114, 0.1017, 0.1069, 0.1390, 0.1128, 0.1041, 0.1106, 0.1085,\n",
       "          0.1049],\n",
       "         [0.1089, 0.1098, 0.1132, 0.1163, 0.1128, 0.1007, 0.1188, 0.1122,\n",
       "          0.1073],\n",
       "         [0.1108, 0.1064, 0.1082, 0.1247, 0.1145, 0.1065, 0.1182, 0.1050,\n",
       "          0.1057],\n",
       "         [0.1025, 0.1163, 0.1173, 0.1075, 0.1068, 0.0992, 0.1205, 0.1175,\n",
       "          0.1122]],\n",
       "\n",
       "        [[0.1050, 0.1125, 0.1082, 0.1177, 0.1079, 0.1078, 0.1175, 0.1159,\n",
       "          0.1074],\n",
       "         [0.1163, 0.1084, 0.1113, 0.1164, 0.1122, 0.0987, 0.1225, 0.1116,\n",
       "          0.1025],\n",
       "         [0.1061, 0.1098, 0.1136, 0.1253, 0.1095, 0.0967, 0.1123, 0.1147,\n",
       "          0.1119],\n",
       "         [0.1111, 0.1036, 0.1047, 0.1370, 0.1215, 0.1052, 0.1068, 0.1055,\n",
       "          0.1047],\n",
       "         [0.1067, 0.1134, 0.1068, 0.1265, 0.1094, 0.0961, 0.1133, 0.1233,\n",
       "          0.1045],\n",
       "         [0.1114, 0.1017, 0.1069, 0.1390, 0.1128, 0.1041, 0.1106, 0.1085,\n",
       "          0.1049],\n",
       "         [0.1089, 0.1098, 0.1132, 0.1163, 0.1128, 0.1007, 0.1188, 0.1122,\n",
       "          0.1073],\n",
       "         [0.1108, 0.1064, 0.1082, 0.1247, 0.1145, 0.1065, 0.1182, 0.1050,\n",
       "          0.1057],\n",
       "         [0.1025, 0.1163, 0.1173, 0.1075, 0.1068, 0.0992, 0.1205, 0.1175,\n",
       "          0.1122]],\n",
       "\n",
       "        [[0.1050, 0.1125, 0.1082, 0.1177, 0.1079, 0.1078, 0.1175, 0.1159,\n",
       "          0.1074],\n",
       "         [0.1163, 0.1084, 0.1113, 0.1164, 0.1122, 0.0987, 0.1225, 0.1116,\n",
       "          0.1025],\n",
       "         [0.1061, 0.1098, 0.1136, 0.1253, 0.1095, 0.0967, 0.1123, 0.1147,\n",
       "          0.1119],\n",
       "         [0.1111, 0.1036, 0.1047, 0.1370, 0.1215, 0.1052, 0.1068, 0.1055,\n",
       "          0.1047],\n",
       "         [0.1067, 0.1134, 0.1068, 0.1265, 0.1094, 0.0961, 0.1133, 0.1233,\n",
       "          0.1045],\n",
       "         [0.1114, 0.1017, 0.1069, 0.1390, 0.1128, 0.1041, 0.1106, 0.1085,\n",
       "          0.1049],\n",
       "         [0.1089, 0.1098, 0.1132, 0.1163, 0.1128, 0.1007, 0.1188, 0.1122,\n",
       "          0.1073],\n",
       "         [0.1108, 0.1064, 0.1082, 0.1247, 0.1145, 0.1065, 0.1182, 0.1050,\n",
       "          0.1057],\n",
       "         [0.1025, 0.1163, 0.1173, 0.1075, 0.1068, 0.0992, 0.1205, 0.1175,\n",
       "          0.1122]]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.functional.softmax(score, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_mha1_out = clf.q_mha1(q_sent_mat, q_sent_mat, q_sent_mat, q_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0391,  0.0480,  0.0301,  ...,  0.0084,  0.0334, -0.0837],\n",
       "         [ 0.0528,  0.0073,  0.0112,  ...,  0.0315, -0.0214, -0.0647],\n",
       "         [ 0.0707,  0.0431,  0.0256,  ...,  0.0258,  0.0221, -0.0971],\n",
       "         ...,\n",
       "         [ 0.0401,  0.0335,  0.0406,  ...,  0.0163, -0.0285, -0.0727],\n",
       "         [ 0.0417,  0.0231,  0.0361,  ...,  0.0317, -0.0031, -0.0394],\n",
       "         [ 0.0630,  0.0205,  0.0040,  ...,  0.0018,  0.0130, -0.1145]],\n",
       "\n",
       "        [[ 0.0552,  0.0529,  0.0488,  ...,  0.0360,  0.0058, -0.0817],\n",
       "         [ 0.0346,  0.0479,  0.0558,  ..., -0.0444,  0.0386, -0.0810],\n",
       "         [ 0.0501,  0.0359,  0.0252,  ..., -0.0006,  0.0147, -0.0492],\n",
       "         ...,\n",
       "         [ 0.0582,  0.0501,  0.0348,  ...,  0.0268,  0.0228, -0.0906],\n",
       "         [ 0.0644,  0.0444,  0.0361,  ..., -0.0050,  0.0139, -0.1152],\n",
       "         [ 0.0408,  0.0315,  0.0522,  ..., -0.0022, -0.0048, -0.0832]],\n",
       "\n",
       "        [[ 0.0404,  0.0314,  0.0256,  ..., -0.0222,  0.0002, -0.0634],\n",
       "         [ 0.0414,  0.0298,  0.0121,  ...,  0.0458, -0.0175, -0.0628],\n",
       "         [ 0.0892,  0.0343,  0.0116,  ...,  0.0000,  0.0383, -0.1261],\n",
       "         ...,\n",
       "         [ 0.0353,  0.0660,  0.0204,  ...,  0.0381, -0.0184, -0.0780],\n",
       "         [ 0.0730,  0.0545,  0.0202,  ...,  0.0149,  0.0152, -0.0840],\n",
       "         [ 0.0461,  0.0644,  0.0460,  ...,  0.0372, -0.0175, -0.1130]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.0956,  0.0295, -0.0621,  ...,  0.0755, -0.0814, -0.0049],\n",
       "         [ 0.0904,  0.0547, -0.0693,  ...,  0.0509, -0.0489, -0.0308],\n",
       "         [ 0.1018,  0.0176, -0.0024,  ...,  0.0594, -0.0562, -0.0264],\n",
       "         ...,\n",
       "         [ 0.1177,  0.0473,  0.0104,  ...,  0.0339, -0.0519, -0.0352],\n",
       "         [ 0.1334,  0.0238, -0.0230,  ...,  0.0906, -0.0574, -0.0268],\n",
       "         [ 0.1091,  0.0223,  0.0178,  ...,  0.0753, -0.0528, -0.0533]],\n",
       "\n",
       "        [[ 0.1108,  0.0389,  0.0276,  ...,  0.0427, -0.0308, -0.0270],\n",
       "         [ 0.1391,  0.0239,  0.0209,  ...,  0.0538, -0.0611, -0.0195],\n",
       "         [ 0.1261,  0.0179, -0.0225,  ...,  0.0999, -0.0745, -0.0314],\n",
       "         ...,\n",
       "         [ 0.0920,  0.0187, -0.0435,  ...,  0.0398, -0.0583, -0.0174],\n",
       "         [ 0.1038,  0.0242, -0.0096,  ...,  0.0588, -0.0547, -0.0177],\n",
       "         [ 0.0982,  0.0221,  0.0189,  ...,  0.0493, -0.0360, -0.0190]],\n",
       "\n",
       "        [[ 0.1372,  0.0123, -0.0179,  ...,  0.0657, -0.0797,  0.0127],\n",
       "         [ 0.1035,  0.0526, -0.0076,  ...,  0.0332, -0.0443, -0.0541],\n",
       "         [ 0.1230,  0.0213,  0.0265,  ...,  0.0511, -0.0357, -0.0012],\n",
       "         ...,\n",
       "         [ 0.1286,  0.0154,  0.0540,  ...,  0.0471, -0.0445, -0.0219],\n",
       "         [ 0.1389, -0.0040,  0.0154,  ...,  0.0644, -0.0727, -0.0224],\n",
       "         [ 0.0737,  0.0598,  0.0334,  ...,  0.0262, -0.0219, -0.0692]]],\n",
       "       device='cuda:0', grad_fn=<ThAddBackward>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_mha1_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0028, device='cuda:0', grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_mha1_out.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1089, device='cuda:0', grad_fn=<StdBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_mha1_out.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_mha1_out = clf.a_mha1(a_sent_mat, a_sent_mat, a_sent_mat, a_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LayerNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([0.9947, 0.9934, 1.0030, 1.0016, 0.9930, 1.0005, 1.0011, 1.0006, 1.0002,\n",
      "        0.9945, 0.9977, 0.9944, 1.0037, 0.9961, 0.9966, 1.0029, 0.9966, 0.9940,\n",
      "        0.9966, 0.9926, 0.9956, 0.9970, 0.9993, 1.0022, 0.9934, 0.9982, 0.9941,\n",
      "        1.0013, 0.9977, 0.9986, 1.0014, 1.0043, 1.0031, 0.9890, 1.0099, 0.9898,\n",
      "        0.9944, 0.9970, 1.0007, 0.9907, 0.9964, 0.9997, 1.0002, 0.9962, 0.9932,\n",
      "        1.0001, 0.9965, 0.9933, 0.9944, 1.0029], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0016, -0.0057, -0.0022,  0.0028,  0.0006,  0.0016, -0.0005,  0.0009,\n",
      "        -0.0026,  0.0078,  0.0011,  0.0013,  0.0002, -0.0008,  0.0003, -0.0011,\n",
      "         0.0033,  0.0001,  0.0025, -0.0047,  0.0023,  0.0007,  0.0038,  0.0002,\n",
      "         0.0025,  0.0027, -0.0053, -0.0005,  0.0009, -0.0072,  0.0023, -0.0021,\n",
      "        -0.0042,  0.0047, -0.0032, -0.0007, -0.0034,  0.0037,  0.0033,  0.0022,\n",
      "        -0.0031, -0.0016,  0.0026,  0.0037, -0.0013,  0.0039,  0.0003, -0.0093,\n",
      "        -0.0022, -0.0001], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(clf.q_layer_norms[0].weight)\n",
    "print(clf.q_layer_norms[0].bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([1.0114, 0.9989, 1.0138, 1.0031, 1.0166, 1.0082, 1.0045, 1.0245, 1.0204,\n",
      "        0.9838, 0.9908, 1.0070, 0.9895, 1.0107, 0.9965, 0.9879, 0.9918, 0.9999,\n",
      "        0.9820, 1.0116, 1.0160, 1.0184, 1.0014, 1.0062, 0.9837, 1.0219, 1.0033,\n",
      "        0.9924, 1.0056, 1.0006, 1.0245, 0.9931, 1.0027, 1.0019, 1.0030, 1.0104,\n",
      "        1.0042, 0.9970, 1.0086, 0.9894, 1.0044, 1.0008, 1.0073, 0.9959, 1.0131,\n",
      "        1.0180, 1.0126, 1.0036, 1.0159, 0.9910], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0007, -0.0090, -0.0005, -0.0014, -0.0001, -0.0031,  0.0005, -0.0014,\n",
      "        -0.0002,  0.0160, -0.0071,  0.0076, -0.0073,  0.0008, -0.0021, -0.0166,\n",
      "         0.0116,  0.0075,  0.0045,  0.0062,  0.0001,  0.0016,  0.0006, -0.0031,\n",
      "        -0.0128, -0.0016, -0.0001,  0.0046, -0.0000, -0.0067,  0.0106, -0.0186,\n",
      "         0.0112,  0.0029,  0.0049, -0.0039, -0.0009,  0.0100,  0.0039,  0.0012,\n",
      "        -0.0104, -0.0033,  0.0003,  0.0140, -0.0013,  0.0055, -0.0016,  0.0017,\n",
      "        -0.0002, -0.0108], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(clf.a_layer_norms[0].weight)\n",
    "print(clf.a_layer_norms[0].bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.train import train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(clf.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(clf, optimizer, dev_iterator, label_name='label',\n",
    "            num_epoch=1, cuda_device=None, early_stopping=0,\n",
    "            input_names=['q_words', 'a_words'], callback=None, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0117,  0.0000, -0.0012,  0.0000,  0.0000,  0.0000,  0.0000, -0.0213,\n",
       "         -0.0045,  0.0000, -0.0001, -0.0199, -0.0001,  0.0000,  0.0000, -0.0084,\n",
       "         -0.0020, -0.0232,  0.0000, -0.0219, -0.0278, -0.0000, -0.0090, -0.0191,\n",
       "         -0.0110,  0.0000,  0.0000,  0.0000,  0.0000, -0.0005, -0.0197,  0.0000,\n",
       "         -0.0172, -0.0343,  0.0000, -0.0086,  0.0000, -0.0278,  0.0000, -0.0005,\n",
       "         -0.0188, -0.0045,  0.0000, -0.0009,  0.0000, -0.0154,  0.0000, -0.0239,\n",
       "         -0.0141,  0.0000,  0.0000,  0.0000, -0.0034,  0.0000, -0.0063,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000, -0.0150, -0.0044,  0.0000, -0.0144, -0.0445,\n",
       "         -0.0114, -0.0096, -0.0000, -0.0116,  0.0000, -0.0203,  0.0000, -0.0367,\n",
       "         -0.0242, -0.0029, -0.0290,  0.0000,  0.0000, -0.0063, -0.0026, -0.0033,\n",
       "          0.0000,  0.0000,  0.0000, -0.0064, -0.0171,  0.0000, -0.0199,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000, -0.0089, -0.0273, -0.0102,  0.0000, -0.0177,\n",
       "         -0.0007, -0.0359,  0.0000,  0.0000, -0.0104,  0.0000, -0.0000, -0.0013,\n",
       "         -0.0002,  0.0000, -0.0061,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000, -0.0095,  0.0000, -0.0164, -0.0013, -0.0057,  0.0000, -0.0282,\n",
       "         -0.0170,  0.0000,  0.0000, -0.0118,  0.0000, -0.0034,  0.0000,  0.0000,\n",
       "         -0.0000,  0.0000, -0.0026, -0.0150, -0.0046,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000, -0.0046,  0.0000,  0.0000,  0.0000, -0.0280,  0.0000,  0.0000,\n",
       "          0.0000, -0.0026, -0.0128,  0.0000, -0.0067, -0.0137, -0.0066, -0.0047,\n",
       "         -0.0266, -0.0001,  0.0000, -0.0132,  0.0000, -0.0022,  0.0000, -0.0093,\n",
       "         -0.0198,  0.0000, -0.0026, -0.0176,  0.0000,  0.0000, -0.0131, -0.0154,\n",
       "          0.0000,  0.0000, -0.0256,  0.0000, -0.0044,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000, -0.0076, -0.0000, -0.0097,  0.0000, -0.0119, -0.0051, -0.0011,\n",
       "         -0.0043, -0.0258, -0.0033, -0.0134, -0.0199, -0.0035, -0.0128, -0.0074,\n",
       "          0.0000, -0.0105,  0.0000, -0.0021,  0.0000,  0.0000, -0.0033,  0.0000],\n",
       "        [ 0.0117,  0.0000,  0.0012,  0.0000,  0.0000,  0.0000,  0.0000,  0.0213,\n",
       "          0.0045,  0.0000,  0.0001,  0.0199,  0.0001,  0.0000,  0.0000,  0.0084,\n",
       "          0.0020,  0.0232,  0.0000,  0.0219,  0.0278,  0.0000,  0.0090,  0.0191,\n",
       "          0.0110,  0.0000,  0.0000,  0.0000,  0.0000,  0.0005,  0.0197,  0.0000,\n",
       "          0.0172,  0.0343,  0.0000,  0.0086,  0.0000,  0.0278,  0.0000,  0.0005,\n",
       "          0.0188,  0.0045,  0.0000,  0.0009,  0.0000,  0.0154,  0.0000,  0.0239,\n",
       "          0.0141,  0.0000,  0.0000,  0.0000,  0.0034,  0.0000,  0.0063,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0150,  0.0044,  0.0000,  0.0144,  0.0445,\n",
       "          0.0114,  0.0096,  0.0000,  0.0116,  0.0000,  0.0203,  0.0000,  0.0367,\n",
       "          0.0242,  0.0029,  0.0290,  0.0000,  0.0000,  0.0063,  0.0026,  0.0033,\n",
       "          0.0000,  0.0000,  0.0000,  0.0064,  0.0171,  0.0000,  0.0199,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0089,  0.0273,  0.0102,  0.0000,  0.0177,\n",
       "          0.0007,  0.0359,  0.0000,  0.0000,  0.0104,  0.0000,  0.0000,  0.0013,\n",
       "          0.0002,  0.0000,  0.0061,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0095,  0.0000,  0.0164,  0.0013,  0.0057,  0.0000,  0.0282,\n",
       "          0.0170,  0.0000,  0.0000,  0.0118,  0.0000,  0.0034,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0026,  0.0150,  0.0046,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0046,  0.0000,  0.0000,  0.0000,  0.0280,  0.0000,  0.0000,\n",
       "          0.0000,  0.0026,  0.0128,  0.0000,  0.0067,  0.0137,  0.0066,  0.0047,\n",
       "          0.0266,  0.0001,  0.0000,  0.0132,  0.0000,  0.0022,  0.0000,  0.0093,\n",
       "          0.0198,  0.0000,  0.0026,  0.0176,  0.0000,  0.0000,  0.0131,  0.0154,\n",
       "          0.0000,  0.0000,  0.0256,  0.0000,  0.0044,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0076,  0.0000,  0.0097,  0.0000,  0.0119,  0.0051,  0.0011,\n",
       "          0.0043,  0.0258,  0.0033,  0.0134,  0.0199,  0.0035,  0.0128,  0.0074,\n",
       "          0.0000,  0.0105,  0.0000,  0.0021,  0.0000,  0.0000,  0.0033,  0.0000]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.hidden2.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0063)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.hidden2.weight.grad.abs().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0115)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.hidden2.weight.grad[(clf.hidden2.weight.grad != 0)].abs().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(180)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(clf.hidden2.weight.grad == 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 200])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.hidden2.weight.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(18000)\n",
      "torch.Size([200, 200])\n"
     ]
    }
   ],
   "source": [
    "print((clf.hidden1.weight.grad == 0).sum())\n",
    "print(clf.hidden1.weight.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0036,  0.0037, -0.0028,  0.0018,  0.0011, -0.0037, -0.0043,  0.0032,\n",
      "        -0.0009,  0.0008,  0.0048,  0.0002,  0.0006, -0.0015, -0.0018, -0.0004,\n",
      "        -0.0051, -0.0015,  0.0028, -0.0011,  0.0008,  0.0018,  0.0017,  0.0012,\n",
      "         0.0011, -0.0009,  0.0001,  0.0012, -0.0012,  0.0002, -0.0004, -0.0002,\n",
      "         0.0051,  0.0007, -0.0015, -0.0018, -0.0023,  0.0013,  0.0002, -0.0007,\n",
      "        -0.0024, -0.0035,  0.0008,  0.0006, -0.0009, -0.0010, -0.0046,  0.0033,\n",
      "         0.0006, -0.0029])\n",
      "tensor([ 0.0065, -0.0009,  0.0054, -0.0005,  0.0079,  0.0122, -0.0039, -0.0019,\n",
      "         0.0044, -0.0008,  0.0062,  0.0080, -0.0015,  0.0014,  0.0043, -0.0021,\n",
      "         0.0057,  0.0071,  0.0049, -0.0051,  0.0031,  0.0024, -0.0053, -0.0028,\n",
      "         0.0002, -0.0059,  0.0024,  0.0015, -0.0024, -0.0032, -0.0020,  0.0003,\n",
      "        -0.0049, -0.0026,  0.0028, -0.0037, -0.0053, -0.0005, -0.0005,  0.0041,\n",
      "        -0.0067, -0.0015, -0.0054, -0.0016, -0.0024,  0.0059, -0.0091,  0.0065,\n",
      "        -0.0036, -0.0039])\n"
     ]
    }
   ],
   "source": [
    "print(clf.a_layer_norms[2].weight.grad)\n",
    "print(clf.a_layer_norms[2].bias.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0025,  0.0016, -0.0012,  0.0031,  0.0027, -0.0032, -0.0025,  0.0008,\n",
      "         0.0001, -0.0004,  0.0058,  0.0032,  0.0008, -0.0023, -0.0022, -0.0001,\n",
      "        -0.0080, -0.0009,  0.0014, -0.0016,  0.0006,  0.0022,  0.0020,  0.0029,\n",
      "         0.0017,  0.0022,  0.0015,  0.0010,  0.0000, -0.0001, -0.0011, -0.0009,\n",
      "         0.0070,  0.0011, -0.0020, -0.0014, -0.0011,  0.0008, -0.0000, -0.0012,\n",
      "        -0.0026, -0.0025,  0.0019,  0.0010, -0.0019, -0.0009, -0.0034,  0.0058,\n",
      "         0.0005, -0.0060])\n",
      "tensor([ 0.0072, -0.0013,  0.0061, -0.0014,  0.0075,  0.0134, -0.0044, -0.0001,\n",
      "         0.0037,  0.0001,  0.0054,  0.0068, -0.0015,  0.0015,  0.0023, -0.0008,\n",
      "         0.0062,  0.0069,  0.0021, -0.0064,  0.0033,  0.0021, -0.0052, -0.0014,\n",
      "         0.0006, -0.0031,  0.0042,  0.0012, -0.0010, -0.0017, -0.0027, -0.0004,\n",
      "        -0.0053, -0.0016,  0.0027, -0.0044, -0.0047, -0.0019, -0.0020,  0.0014,\n",
      "        -0.0067, -0.0014, -0.0058, -0.0027, -0.0033,  0.0050, -0.0088,  0.0046,\n",
      "        -0.0037, -0.0047])\n"
     ]
    }
   ],
   "source": [
    "print(clf.a_layer_norms[1].weight.grad)\n",
    "print(clf.a_layer_norms[1].bias.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0027,  0.0011, -0.0020,  0.0023,  0.0029, -0.0033, -0.0024,  0.0008,\n",
      "         0.0008, -0.0003,  0.0074,  0.0040,  0.0005, -0.0023, -0.0020,  0.0000,\n",
      "        -0.0067, -0.0027,  0.0006, -0.0004,  0.0001,  0.0021,  0.0015,  0.0029,\n",
      "         0.0021,  0.0019,  0.0013,  0.0006,  0.0005, -0.0005, -0.0010, -0.0009,\n",
      "         0.0080,  0.0015, -0.0019, -0.0019, -0.0022,  0.0007,  0.0006, -0.0013,\n",
      "        -0.0025, -0.0020,  0.0013,  0.0017, -0.0023,  0.0006, -0.0043,  0.0056,\n",
      "         0.0001, -0.0074])\n",
      "tensor([ 0.0071, -0.0020,  0.0069, -0.0019,  0.0079,  0.0138, -0.0048,  0.0002,\n",
      "         0.0034, -0.0002,  0.0057,  0.0064, -0.0016,  0.0015,  0.0026, -0.0007,\n",
      "         0.0057,  0.0068,  0.0022, -0.0069,  0.0028,  0.0026, -0.0057, -0.0010,\n",
      "         0.0012, -0.0034,  0.0042,  0.0019, -0.0003, -0.0023, -0.0033, -0.0002,\n",
      "        -0.0058, -0.0024,  0.0032, -0.0046, -0.0047, -0.0014, -0.0024,  0.0008,\n",
      "        -0.0067, -0.0008, -0.0055, -0.0035, -0.0041,  0.0049, -0.0091,  0.0040,\n",
      "        -0.0041, -0.0050])\n"
     ]
    }
   ],
   "source": [
    "print(clf.a_layer_norms[0].weight.grad)\n",
    "print(clf.a_layer_norms[0].bias.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0002,  0.0018, -0.0005,  ..., -0.0007, -0.0000, -0.0006],\n",
      "        [ 0.0001,  0.0018, -0.0002,  ..., -0.0016, -0.0008, -0.0002],\n",
      "        [ 0.0003,  0.0007, -0.0006,  ..., -0.0006, -0.0003, -0.0007],\n",
      "        ...,\n",
      "        [ 0.0003,  0.0006, -0.0001,  ...,  0.0004,  0.0002, -0.0002],\n",
      "        [ 0.0004, -0.0005, -0.0000,  ..., -0.0009, -0.0004, -0.0001],\n",
      "        [ 0.0004,  0.0000, -0.0007,  ...,  0.0001,  0.0005, -0.0001]])\n",
      "tensor([-0.0010, -0.0005, -0.0002,  0.0002,  0.0001,  0.0020, -0.0010, -0.0000,\n",
      "        -0.0011,  0.0004,  0.0002,  0.0015, -0.0008, -0.0001, -0.0005,  0.0000,\n",
      "        -0.0004, -0.0004, -0.0005, -0.0006,  0.0008,  0.0007,  0.0008, -0.0007,\n",
      "         0.0012,  0.0012, -0.0001,  0.0008,  0.0001, -0.0001, -0.0012,  0.0004,\n",
      "         0.0022,  0.0004,  0.0007, -0.0006,  0.0006, -0.0006,  0.0022, -0.0004,\n",
      "        -0.0014, -0.0012, -0.0000,  0.0001,  0.0003,  0.0012,  0.0005,  0.0028,\n",
      "         0.0002,  0.0010,  0.0017,  0.0004, -0.0008,  0.0006, -0.0004, -0.0014,\n",
      "        -0.0006,  0.0009,  0.0006, -0.0007, -0.0001,  0.0002, -0.0009,  0.0011,\n",
      "        -0.0005, -0.0000,  0.0004,  0.0018,  0.0009,  0.0001,  0.0010,  0.0005,\n",
      "         0.0004,  0.0013, -0.0010,  0.0028,  0.0002,  0.0002,  0.0005,  0.0014,\n",
      "        -0.0001, -0.0007,  0.0002,  0.0021,  0.0011, -0.0004, -0.0021, -0.0007,\n",
      "        -0.0000, -0.0001,  0.0009, -0.0001,  0.0004,  0.0014,  0.0005, -0.0009,\n",
      "         0.0001, -0.0011,  0.0012,  0.0003, -0.0012, -0.0005,  0.0007, -0.0014,\n",
      "         0.0012, -0.0003, -0.0021,  0.0003,  0.0002, -0.0014,  0.0020,  0.0001,\n",
      "         0.0010, -0.0005,  0.0001, -0.0000, -0.0003, -0.0011, -0.0001, -0.0001,\n",
      "         0.0003,  0.0009, -0.0012,  0.0013, -0.0027,  0.0002,  0.0001, -0.0003])\n"
     ]
    }
   ],
   "source": [
    "print(clf.a_ffn.w_1.weight.grad)\n",
    "print(clf.a_ffn.w_1.bias.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0016,  0.0007,  0.0002,  ...,  0.0010,  0.0009,  0.0008],\n",
      "        [-0.0012,  0.0012, -0.0009,  ...,  0.0009, -0.0014, -0.0005],\n",
      "        [ 0.0013,  0.0011,  0.0005,  ...,  0.0012,  0.0012, -0.0000],\n",
      "        ...,\n",
      "        [ 0.0017, -0.0000,  0.0004,  ..., -0.0001,  0.0010,  0.0005],\n",
      "        [-0.0006, -0.0004, -0.0005,  ..., -0.0004, -0.0011, -0.0007],\n",
      "        [-0.0019,  0.0003, -0.0013,  ..., -0.0001, -0.0012, -0.0007]])\n",
      "tensor([ 0.0059,  0.0003,  0.0053, -0.0022,  0.0072,  0.0119, -0.0041, -0.0006,\n",
      "         0.0035, -0.0010,  0.0045,  0.0066, -0.0018,  0.0010,  0.0036, -0.0023,\n",
      "         0.0053,  0.0065,  0.0040, -0.0058,  0.0030,  0.0020, -0.0047, -0.0022,\n",
      "        -0.0006, -0.0041,  0.0021,  0.0021, -0.0009, -0.0036, -0.0025,  0.0005,\n",
      "        -0.0048, -0.0019,  0.0017, -0.0040, -0.0048, -0.0016, -0.0013,  0.0026,\n",
      "        -0.0065, -0.0021, -0.0043, -0.0020, -0.0024,  0.0054, -0.0090,  0.0044,\n",
      "        -0.0043, -0.0040])\n"
     ]
    }
   ],
   "source": [
    "print(clf.a_ffn.w_2.weight.grad)\n",
    "print(clf.a_ffn.w_2.bias.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0001, -0.0000,  0.0000,  ..., -0.0000, -0.0000,  0.0001],\n",
      "        [-0.0001,  0.0001,  0.0001,  ..., -0.0001, -0.0001, -0.0000],\n",
      "        [-0.0002,  0.0001,  0.0002,  ..., -0.0002, -0.0002,  0.0001],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000, -0.0001,  ..., -0.0003, -0.0002, -0.0001],\n",
      "        [ 0.0000, -0.0003, -0.0001,  ...,  0.0004,  0.0004, -0.0000],\n",
      "        [ 0.0000,  0.0003, -0.0002,  ..., -0.0004, -0.0003, -0.0001]])\n",
      "tensor([ 1.0959e-04,  1.6361e-05,  1.7401e-04,  7.2125e-05,  3.2807e-04,\n",
      "        -1.0629e-04,  5.3922e-05,  2.5753e-04, -3.0069e-04,  4.5623e-04,\n",
      "        -2.4182e-04,  1.2838e-04, -1.1899e-05,  1.2362e-04, -1.9651e-04,\n",
      "        -3.9662e-05,  1.5254e-04, -3.1538e-05, -2.1276e-04,  1.5623e-04,\n",
      "         4.0863e-05, -1.2068e-04,  2.0957e-04, -2.0596e-04,  3.2331e-04,\n",
      "        -2.5232e-05,  2.9107e-04, -3.0936e-04, -2.4949e-04,  2.9088e-04,\n",
      "         8.3857e-05,  4.3533e-04,  1.9532e-05,  8.8340e-05,  2.8200e-05,\n",
      "         5.6540e-05,  1.2819e-04, -5.9726e-05, -4.0417e-05,  1.1805e-04,\n",
      "        -5.7158e-04,  4.9823e-04, -1.0349e-04, -7.3387e-04, -5.9084e-04,\n",
      "         8.0458e-06, -1.0413e-04,  7.0807e-06, -4.6211e-05, -6.9635e-05])\n"
     ]
    }
   ],
   "source": [
    "print(clf.a_mha2.linears[0].weight.grad)\n",
    "print(clf.a_mha2.linears[0].bias.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.7186e-06, -9.2845e-06, -5.5886e-08,  ..., -3.2881e-06,\n",
      "         -1.6022e-05,  2.9972e-06],\n",
      "        [ 6.1626e-06, -1.7645e-05, -2.1505e-06,  ..., -1.2584e-06,\n",
      "         -5.6265e-06,  4.4611e-06],\n",
      "        [ 5.1153e-06, -2.4945e-05, -6.8601e-06,  ..., -1.8162e-05,\n",
      "         -2.2849e-05, -8.4422e-07],\n",
      "        ...,\n",
      "        [-4.3891e-05, -5.2141e-06,  5.0523e-05,  ...,  2.2805e-05,\n",
      "         -3.6387e-05, -7.9094e-06],\n",
      "        [ 1.8308e-05,  1.6312e-06, -2.8325e-05,  ...,  6.5529e-06,\n",
      "          3.0644e-05,  6.6337e-07],\n",
      "        [-3.4199e-06,  1.0917e-06,  4.0286e-06,  ...,  7.3655e-06,\n",
      "         -2.0266e-06, -1.8547e-06]])\n",
      "tensor([ 1.0380e-04,  6.1468e-05,  1.7917e-04,  5.8693e-05, -1.5743e-04,\n",
      "        -2.4759e-04,  9.6750e-05,  4.4369e-05, -2.0534e-04,  2.7656e-06,\n",
      "        -2.4453e-04,  8.1951e-05, -2.2206e-04, -2.4834e-04, -1.8574e-04,\n",
      "        -3.7961e-04,  1.5967e-04,  1.3082e-04, -1.5971e-04,  2.3459e-04,\n",
      "         8.1737e-05, -9.6855e-06,  1.9250e-05,  3.9176e-05,  3.2481e-05,\n",
      "        -6.4515e-06,  8.2895e-05,  4.9999e-06,  3.9423e-05,  3.6900e-05,\n",
      "        -8.4374e-05,  3.7139e-05,  7.0681e-05, -4.8289e-05, -7.9437e-05,\n",
      "         1.1913e-04, -5.5438e-05, -1.7229e-05, -2.4022e-04, -1.3992e-04,\n",
      "         7.3812e-05, -1.0409e-04,  3.0896e-05,  6.4076e-05,  3.7397e-05,\n",
      "         1.0614e-04,  2.2229e-05,  3.0112e-04, -1.8730e-04,  4.9615e-05])\n"
     ]
    }
   ],
   "source": [
    "print(clf.a_mha1.linears[0].weight.grad)\n",
    "print(clf.a_mha1.linears[0].bias.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0001)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.a_mha2.linears[0].weight.grad.abs().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0002)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.a_mha2.linears[0].bias.grad.abs().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([1.0235, 1.0012, 1.0278, 1.0119, 1.0284, 1.0133, 1.0087, 1.0258, 1.0317,\n",
       "        0.9790, 0.9916, 1.0137, 1.0016, 1.0287, 0.9850, 0.9813, 0.9918, 1.0067,\n",
       "        0.9829, 1.0214, 1.0357, 1.0270, 0.9903, 1.0136, 0.9757, 1.0252, 1.0011,\n",
       "        0.9784, 1.0164, 0.9943, 1.0281, 0.9892, 1.0110, 1.0079, 1.0040, 1.0125,\n",
       "        1.0040, 0.9930, 1.0119, 0.9847, 1.0086, 1.0036, 1.0104, 0.9935, 1.0228,\n",
       "        1.0238, 1.0135, 1.0081, 1.0214, 0.9853], requires_grad=True)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.a_layer_norms[0].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0350,  0.1171, -0.0649,  ...,  0.0499,  0.1135,  0.1156],\n",
       "        [-0.1175,  0.1073, -0.0445,  ...,  0.0252,  0.0126, -0.1079],\n",
       "        [-0.1208, -0.0053, -0.0589,  ..., -0.0507, -0.1120, -0.1375],\n",
       "        ...,\n",
       "        [-0.0391, -0.1288, -0.0262,  ..., -0.0056,  0.0013, -0.0043],\n",
       "        [-0.1538, -0.1448,  0.0040,  ..., -0.0467, -0.0330,  0.0321],\n",
       "        [-0.0521, -0.1164,  0.0519,  ...,  0.0520, -0.1157,  0.0291]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.a_mha2.linears[0].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0892, -0.0708,  0.1139,  ..., -0.0102,  0.0059,  0.0893],\n",
       "        [ 0.0974,  0.0504, -0.0525,  ..., -0.0387,  0.0901, -0.0687],\n",
       "        [ 0.1484,  0.0394,  0.1242,  ..., -0.1020, -0.1252,  0.1021],\n",
       "        ...,\n",
       "        [ 0.0173,  0.0598, -0.0717,  ...,  0.0524,  0.1177, -0.0117],\n",
       "        [-0.1055,  0.0173, -0.0266,  ...,  0.1139,  0.1239,  0.0277],\n",
       "        [-0.1092, -0.1123,  0.0468,  ..., -0.0754,  0.1144,  0.1307]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.a_mha2.linears[3].weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO 입력에 layernorm + sqrt(d_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
